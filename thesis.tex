\documentclass[11pt, a4paper]{report}
\clubpenalty=10000
\widowpenalty=10000
\usepackage{fullpage}
\usepackage{epsfig}
\usepackage{setspace}
\usepackage{latexsym}
\usepackage{algorithmic}
\usepackage{algorithm}
\usepackage{epsfig}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{subfigure}
\usepackage[usenames]{color}
\usepackage{verbatim}

\newcommand\todo[1]{\textcolor{Red}{\textbf{#1}}}
\newcommand\pOlost{\textrm{$P_0$ is lost}}
\newcommand\QED{\hfill\ensuremath{\Box}}
\let\showproof1


\newtheorem{lemma}{Lemma}
\newtheorem{theorem}{Theorem}
\newenvironment{proof}[1][Proof]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}


\title{Streaming of High-Resolution Progressive Meshes Over Network}
\author{Wei CHENG\\
National University of Singapore\\
SuperVisor\\
Wei Tsang OOI}
\begin{document}
\maketitle
\doublespacing
\begin{abstract}
    \begin{comment}
    High-resolution 3D meshes are increasingly available in networked
    applications, such as digital museum, online game, and virtual reality.
    The amount of data constituting a high-resolution 3D mesh can be
    huge, leading to a long downloading time. 
    To reduce the waiting time of users, 
    a common technique for remote viewing is progressive streaming,
    which allows a low-resolution version of the mesh to be transmitted
    and rendered with low latency. Then the quality of the transmitted 
    mesh can be incrementally improved when the refinement information
    is continuously being transmitted.

    Progressive mesh is commonly used to support progressive
    streaming. A progressive mesh comprises a \emph{base mesh} and a series
    of refinements. The base mesh is obtained by simplifying the original mesh
    with a series of \emph{edge collapses}.
    With the \emph{vertex splits}, the inverses of these edge
    collapses, the original mesh can be reconstructed from the base mesh.
    Therefore, progressive streaming can be implemented by sending the vertex
    splits as refinements after sending the base mesh.

    Although streaming of videos is extensively studied, 
    streaming of high-resolution progressive meshes is considerably different.
    Frames of a video are usually sent following the time order,
    vertex splits of a progressive mesh, however, can be sent in various of orders.
    Some new research problems arise due to the flexibility in sending order of 
    vertex splits. In this thesis, four related topics are discussed. 
    %After decoding, each frame contributes the same to a video, but vertex splits
    %in a progressive mesh vary considerably in their contribution to the quality
    %of the reconstructed mesh. 
       
    First, 
    %the effect of dependency needs to be considered in choosing
    %the sending order of vertex splits.
    the progressive coding of meshes introduces dependencies among 
    the vertex splits, and the descendants cannot be decoded
    before their ancestors are all decoded. Therefore, 
    when a progressive mesh is transmitted over a lossy network,
    a packet loss will delay the decoding of the following
    vertex splits if they depend on this lost packet. 
    %These successfully received vertex splits cannot be 
    %decoded until the lost packet is successfully retransmitted. 
    Hence, the effect of dependency needs to
    be considered in choosing the sending order of vertex splits. 
    %To find the effect of dependency
    %is non-trivial as the packet loss happens randomly.
    In this thesis, an analytical model is proposed to 
    %quantify the effect of dependency on the quality curve.
    quantitatively analyzes the effects of dependency
    by modeling the distribution of decoding time of each vertex split
    as a function of mesh properties and network parameters.
    %The quality curve is determined by the decoding time of the vertex
    %splits and their contributions to the overall mesh quality.    
    %The decoding time of a vertex split depends on its receiving time and the 
    %receiving time of its all ancestors. The receiving time of a vertex split
    %in turn depends on its sending time and how many times it is 
    %transmitted. 
    %Hence, the distribution of decoding time of each vertex split
    %is modeled as a function of the mesh property and the network condition.
    %From this expression, %both the expected value and 
    %the distribution of the decoding time of each
    %vertex split can be efficiently computed before transmission. 
    Consequently, Different sending orders can be  
    efficiently evaluated without simulations, 
    and this model can help in developing a sending
    strategy to improve the quality curve 
    during transmission. % to improve the quality.
    
    Furthermore, %closed-form expressions are derived in two extreme cases,
    this model is applied to study two extreme cases of dependency in 
    progressive meshes and
    %providing insights to the importance of dependencies on the
    %decoded mesh quality. 
    The main insight found is that if each lost packet
    is immediately retransmitted upon the packet loss is detected, 
    the effect of dependencies on decoded mesh quality diminishes with time.
    %the dependencies only matters in the first several round trip times. 
    Therefore, the effect of dependency is only significant in the applications
    requiring high interactivity. 

    The accuracy of the analylitical model proposed in this thesis is validated
    under a variety of network conditions, including bursty losses, fluctuating RTT,
    and varying sending rate. The values predicted from our model match the measured
    value reasonably well in all cases except when losses are too bursty.
    
    To further improve the quality curve, the view-point of the 
    user can be considered in deciding the sending order.
    %Usually, users can only see a part of a mesh, so sending non-visible data
    %before visible data wastes bandwidth. Moreover, 
    Non-visible vertex splits do not need to be sent, and 
    the visual contributions of visible vertex splits (how much they can improve the rendered image)
    also depend on the view-point of the user.
    Hence, choosing the sending order according to the viewpoint of the user, so called
    \emph{view-dependent streaming}, is a natural choice.
    
    In existing solutions to view-dependent streaming,  the
    sender decides the sending order. 
    %This sender-driven protocol has several
    %drawbacks. First, it is not scalable to many receivers as the sender has to
    %determine the visibility of vertices and sort the visible vertex splits based on their
    %visual contributions for each receiver. 
    %Second, 
    The sender needs to maintain
    the rendering state of each receiver to avoid sending duplicate data. 
    Due to the stateful design %and high computational requirements,
    the sender-driven approach cannot be easily extended to support 
    many receivers with caching proxy and peer-to-peer system,
    two common solutions to scalability. 

    In this thesis, a receiver-driven protocol is proposed to 
    improve the scalability. In this protocol, the receiver decides the sending order
    and explicitly requests the vertex splits, 
    while the sender simply sends the data requested.
    The sending order is computed at the receiver  by estimating the visibility
    and visual contributions of the refinements, even before receiving them,
    with the help of GPU.

    Because the visibility determination and state maintenance are all done by the receivers, 
    the sender in our receiver-driven protocol is stateless and free of complex computation.
    Furthermore, caching proxy and P2P streaming systems can be applied to improve
    the scalability without adding more servers.  
    
    The receiver-driven protocol significantly reduces the computing cost at the sender,
    but the bandwidth can remain the bottleneck if each receiver receives data
    from the same sender. 
    Based on the receiver-driven protocol, P2P techniques are applied to mesh
    streaming in this thesis. In the implementation of P2P mesh streaming system,
    two issues are considered: how to partition a progressive mesh into chunks and 
    how to lookup the provider of a chunk. For the latter issus, we investigated 
    into two solutions, which trade off server overhead and response time. The first
    uses a simple centralized lookup service, while the second organizes peers into
    groups according to the hierarchical structure of the progressive mesh to 
    take advantage of access pattern. Simulation results show that our 
    proposed systems are robust under high churn rate, reduce the server overhead
    by more than $90\%$, keep control overhead below $10\%s$, and achieve
    low average response time.
\end{comment}
\end{abstract}
\chapter{Introduction}
\label{c:intro}
    Advances in 3D scanning technology and 3D modeling
    techniques have enabled creations of huge,
    high-resolution, 3D models.  
    For instance, software such as
    ZBrush is enabling easy creation of complex digital sculpture.
    The Stanford's Digital Michelangelo Project
    \cite{levoy00digital} digitized statues made by Michelangelo
    and provided a software, ScanView \cite{koller04protected},
    to allow users to remotely view the 3D version of the statues.
    Similar projects include the Digital Sculpture Project \cite{deroos2004dsp}
    and the project to digitize Rodin's sculptures \cite{miyazaki2006dab}. 

    Traditionally, networked applications such as 3D games 
    store all data of 3D models in users' local disks, 
    but now some networked applications store the data on the server side 
    and transmit them from the server to users when they are needed. 
    The latter method has several advantages. 
    First, users can immediately start the application without buying a CD
    or downloading large amount of data. 
    Second, because the 3D data are stored in the server and shared by all the users, 
    users can create and modify objects and others can see the new objects immediately. 
    For example, many objects in Second Life are user-created, 
    and this feature is believed to be essential to success of Second Life. 

    High resolution 3D models may take long time to download completely
    for display at the client. 
    For example, the Stanford model of the David statue, with 28 million vertices and
    56 million triangles, is still 70 MB in size with
    state-of-the-art compression \cite{alliez2001progressive} and needs around 10 minutes
    to download at 1 Mbps.
    
    To reduce the waiting time of the user, 
    the streaming technology can be used to transmit 3D models. 
    The 3D streaming technology enables users to render the partially received data as a preview, 
    and then improve the quality when more data are available. 
    Users can decide how many data to receive based on their requirement of quality
    and the rendering ability of their hardware. 

    Although audio and video streaming have been studied extensively, 
    3D streaming remains a new research area. 
    Video streaming and 3D streaming are significantly different
    due to the difference between videos and the representations of 3D models. 
    The main difference is how users consume the data.
    In video streaming, usually the data are consumed in time order. 
    Whereas in 3D streaming, especially when high-resolution 3D models are used,
    users may consume different subset of the data, and in various orders.
    
    This flexibility is important in streaming of high-resolution 3D models, 
    because streaming a huge 3D model in a fix order may waste time and bandwidth in 
    transmitting lots of data not useful to the user. 
    To ensure this flexibility in streaming system is an important consideration.
    Meanwhile, this flexibility introduces some new research questions, 
    which are the main topics of this thesis.
    Before introducing these new research questions,
    it is important to introduce some backgrounds and related works.
    
    \section{Backgrounds and Related Works}
    \subsection{Representation}
    \label{s:intro:representation}
    A 3D object is represented with a certain model.
    Currently the most popular representation of 3D objects is polygonal meshes, 
    especially the triangle meshes, because most graphic cards are optimized for triangle meshes. 

    A triangle mesh can be donated as a tuple $(K, V)$, where $K$ is a
    \emph{simplicial complex} including all the mesh simplices 
    (vertices, edges and triangles) and $V =\{v_{1}, v_{2}, ...,
    v_{n}\}$ is the set of geometry positions of vertices. Therefore,
    a mesh has both \emph{connectivity} information represented by $K$
    and \emph{geometry information} represented by $V$. In another
    word, $K$ includes all the topology information of all the
    elements in the mesh, and with $V$ it is embedded into $R^{3}$. If
    polygons are allowed in $K$ instead of only triangles, then this
    kind of meshes are called polygonal meshes.

    In a mesh, it is required that every
    vertex is an end of an edge and every edge should be incident to at
    least one face ((a) in figure \ref{mesh_non_mesh} is not a mesh).
    The number of edges incident to a vertex is called the
    \emph{valence} of this vertex, and the number of edges incident to
    a face is called the \emph{degree} of this face. An edge only
    incident to one face is called a \emph{boundary edge}; an edge
    shared by two faces is called an \emph{interior edge}; an edge
    shared by more than two faces is called a \emph{singular edge}. A
    \emph{manifold mesh} is a mesh without singular edges and every
    two faces share one edge or nothing (see figure \ref{mesh_non_mesh}).
\begin{figure}
\centering
\includegraphics[width=0.8\textwidth]{figure2.1.eps}
\caption[Manifold mesh, non-manifold mesh and non-mesh]{ (a) is not
a mesh since one edge is incident to no face. (b) is a manifold
mesh. (c) is a non-manifold mesh since there is a singular edge.
(d) is a non-manifold mesh since two faces share only a
vertex.\label{mesh_non_mesh}}\
\end{figure}

    Polygonal meshes can be used as an approximation of the surfaces
    of 3D objects. In this case, some properties of the surface such
    as color and normal are often associated to the mesh. These
    properties can be categorized into two types: discrete attributes
    and scalar attributes \label{property}. Discrete attributes, such
    as material identifier, are usually associated to the faces, while
    scalar attributes, such as color, normal, and texture coordinate,
    are often associated to vertices or corners (the tuple (vertex,
    face)). The latter one is used because in the case of
    discontinuity, a vertex can have more than one scalar value. For
    example, if two smooth surface intersect at a curve, then vertices
    in this curve will have two different normal values. Therefore,
    the normal value should be associated to the tuple (vertex face).
    Then, polygonal meshes can be represented by $(K, V, D, S)$ where
    $D$ is the set of discrete attributes associated to face $f \in
    K$ and $S$ is the set of scalar attributes associated to corners $(v, f)$ in $S$.
    
    Besides meshes, point-based representations are also used in the practice.
    A point-based geometry representation can be considered as a 
    sampling of a continuous surface.  The result are a set of 3D points. 
    %These points are optionally associated with the normal vectors 
    %and other attributes, such as color and material properties. 
    To bridge the gaps between neighboring point samples, 
    bounding spheres \cite{rusinkiewicz:qsplat, 364350} or surface splats \cite{383300} are used as rendering primitives. 
    More details about point based model can be seen in the survey by Kobbelt and Botsch \cite{DBLP:journals/cg/KobbeltB04} 
    and the PhD thesis of Wand \cite{wand:point}.  
    
    Moreover, some other representations also exist, such as simple solid models used in Second Life
    and generalized cylinders used in representing plants \cite{plant:seb, compact:mondet}.

    %\subsection{Choice in This Thesis}
    This thesis concentrates on meshes because of following reasons:
    \begin{itemize}
        \item Most rendering hardwares are optimized for meshes, so other model need to be convert
            to mesh before rendering either explicitly or implicitly. 
        \item Without connectivity information in the model, point-based model is relatively easier to deal with
            than meshes. Therefore, adapting techniques used in streaming meshes to streaming point-based model
            is easier than the opposite direction.
    \end{itemize}

    \subsection{Coding and Compression}
    A mesh is encoded first before it can be stored or
    transmitted. Coding is to represent a mesh with a sequence of
    digits. Compression is always combined with coding to save the storage space
    or the bandwidth needed in transmission. 
    There are two kinds of coding:
    single-rate coding and progressive coding. 
    Single-rate coded mesh can only be decoded when all data are available 
    whereas progressive coded mesh can be decoded with only part of data are available. 
    We will briefly introduce single-rate coding methods, and then concentrate on
    progressive coding methods, because the latter are more suitable for progressive streaming.
    
    \subsubsection{Single-rate Coding} \label{single_rate}
    In a mesh, three kind of information needs to be coded:
    connectivity, geometry and property. 
    Since most property data are associated to vertices, 
    in many compress algorithms they are treated as same as geometry data or even
    ignored. We introduce connectivity coding first, and then introduce geometry coding briefly.
    
    A triangle mesh is often represented as an array of vertex coordinates
    (geometry information) and an array of triangles (connectivity information). 
    A triangle is represented by the indices of its three vertices.
    In this representation, every vertex is indexed by all the
    triangles to which it is incident. Repeated references introduce
    redundancy. Therefore, triangle strip method is introduced to
    reduce this redundancy. In a triangle strip, a triangle fan, or a
    generalized triangle strip (a mixture of triangle strips and
    triangle fans) (see Figure \ref{strip}), 
    triangles can be represented with one index of vertex
    except the first triangle. 
    Deering \cite{218391} first introduced generalized triangular mesh, 
    which combining the generalized triangle strips with a vertex buffer,
    which is used to further reduce the bits used to represent indices. 
    Furthermore, Chow \cite{267103} introduced a method to
    decompose a mesh into triangle strips. 
    Bajaj, Pascucci and Zhuang \cite{789628} presented a coding method with layered
    decomposition. 
    Typically, a triangle layer is a generalized triangle strip. 
    \begin{figure}[ht]
    \centering
    \includegraphics[width=0.6\textwidth]{strip.eps}
    \caption{(A)The triangle strip, (B)the triangle fan, and (C) the generated triangle strip.}\label{strip}
    \end{figure}

    Taubin and Rossignac \cite{274365} proposed a method named
    \emph{topological surgery}, which changes coding of a manifold
    mesh to coding of two trees: a vertex spanning tree and the dual of the triangles.
    Topological surgery has been implemented in MPEG-4 standard, and more details
    can be seen in the report of Taubin\cite{3d:Taubin}.
    
    Touma and Gotsman \cite{triangle:Touma} introduced a
    valence-driven approach to encode the connectivity by coding the
    valence of all the vertices in a specific traversing order. 
    The performance is further improved
    by Alliez and Desbrun \cite{alliez01valencedriven}, who also proved a
    upper-bound 3.24 bpv, exactly the theoretical value computed
    by Tutte \cite{census:Tutte} after enumerating all possible planar
    graphs.

    Several methods based on triangle conquest have also been
    proposed, such as \emph{cut-border machine} proposed by 
    Gumhold and Stra\ss{}er \cite{280836}.
    A significant advantage of this method is that it can be easily implemented
    in hardware and the decompression is very fast, which
    renders it to be very useful in real-time coding. 
    Another method named \emph{edgebreaker} is presented by Rossignac \cite{614421},
    and it is similar to the cut-border machine but has better
    compress efficiency and much slower decompression speed.
    
    After introduction of connectivity coding, we briefly introduce geometry
    coding. Most single-rate geometry compression methods involve three steps:
    quantization, prediction, and entropy coding.

    In VRML, geometry data is represented with 32 bit floating-point
    number, but this precision is highly beyond the perceiving
    capability of human eyes. Hence, quantization can be performed to
    compress the geometry data. Typically, each coordinate in a mesh is
    uniformly quantized to 8-16 bits integer.

    After quantization of vertex coordinates, prediction is taken in
    encoding by exploiting correlations between adjacent vertex
    coordinates. An effective prediction scheme generates prediction
    errors with highly compact distribution, which can be effectively
    encoded by entropy coders, such as Huffman coder or arithmetic
    coder. 

    More details about single-rate coding can be seen in the tutorial
    by Gotsman, Gumhold, and Kobbelt \cite{gotsman-simplification},
    the survey by Taubin \cite{3d:Taubin}, by Alliez and Gotsman
    \cite{recent:alliez}, and the survey by Peng, Kim and Kuo
    \cite{technologies:peng}.
    
    \subsubsection{Progressive Coding}
    Single-rate coded meshes can only be decoded after they are
    totally received, so they are not suitable for streaming. Therefore,
    some progressive coding schemes have been proposed. According to
    how the original mesh is simplified, these coding scheme can be
    categorized into three classes: progressive mesh based, vertex
    clustering based, and re-meshing based.
    
    \begin{description}
        \item[Vertex Clustering Based] 
            In vertex clustering based schemes, space is divided into cells
            following regular structure such as kd-tree \cite{566591} and 
            octree \cite{1073237}. All vertices inside a cell is represented
            by one delegate. Cells can be further divided into smaller cells
            and the quality of reconstructed model increases. Vertex clustering
            based coding can code geometry information efficiently, but it is 
            difficult to code connectivity information. Moreover, the quality
            of base mesh is poor.

        \item[Re-meshing Based]
            Re-meshing based method only keeps the shape of a model
            and does not keep the accurate topology. 
            A irregular mesh can be converted into a semi-regular mesh
            with similar shape. 
            %In a semi-regular
            %triangle mesh, the valence of most vertices is six, and therefore
            Because of the regularity of the new mesh,
            the connectivity information can be coded almost without cost.
            More details about these algorithms can be seen in the survey by Allienz and Gotsman
            \cite{recent:alliez}, the survey by Peng, Kim and Kuo
            \cite{technologies:peng} and the references therein.
            Besides losing the correct topology information,
            re-meshing based method usually code a mesh as a whole, 
            so there is no flexibility in streaming order.

        \item[Progressive Mesh Based]
            In this thesis, we concentrate on progressive meshes, which provide 
            the finest granularity in choosing streaming order and subset, 
            so we introduce the progressive mesh based coding in more details.
    \end{description}

    The progressive mesh (PM) \label{progressive_mesh}is first
    introduced by Hoppe in 1996 \cite{hoppe96progressive}. In this
    scheme, the simplification is based on \emph{edge collapse}, which
    collapses an edge into a vertex (see Figure \ref{split2}).
    After a series of edge collapse, a coarser \emph{base mesh} remains. 
    Then the PM is constructed by the base mesh and a series of \emph{vertex
    splits}, the inverse of edge collapse, in a reverse order.
    Rendering can be done in receiver side at any time after the base
    mesh is received. More vertex splits received, better
    approximation to the original mesh generated. After all
    the vertex split operations are received, the original mesh can be
    reconstructed without loss. \footnote{quantization error may exist
    when quantization is taken in geometry compression.}

    The base mesh can be encoded with the single-rate coding methods
    introduced in section \ref{single_rate}. Here, we introduce
    how to encode the vertex splits. 
\begin{figure}
\centering
\includegraphics[width=0.5\textwidth]{split2.eps}
\caption{Edge collapse and vertex split}\label{split2}
\end{figure}
    For connectivity
    information, we need to code $s$, $l$, and $r$, and for geometry
    information, we need to code the new position of $v_{s}$ and the
    position of $v_{r}$. If half collapse, which always collapse an
    edge to one of its ends (i.e. $v_{s}$ keeps unchanged), is used, 
    we only need to code the position of $v_r$. 
    
    If the number of vertices in current model is
    $V$, then $s$ can be any one of them, 
    and ${\lceil}log_{2}V{\rceil}$ bits are needed to encode $s$. 
    
    Many compression methods are proposed to reduce this cost.
    Hoppe \cite{efficient:hoppe} present an efficient implementation
    , in which the vertex splits is ordered such that next one
    is as close to current one as possible, and reduce the cost
    from $O(Vlog_{2}V$ to $O(V)$.
    In Karni, Bogomjakov, and Gotsman's paper \cite{602153}, 
    specific order of vertex split is also used to reduce the cost of connectivity. 
    The vertex sequence is generated by recursively cut a mesh to two
    balanced part with minimum cut. With their algorithm, the connectivity can
    be encoded with in average 4.5 bpv. 

    Another idea is to group many vertex splits together, 
    and efficiency will be improved at the cost of coarser granularity. 
    Taubin, Gu\'{e}ziec, Horn, and Lazarus \cite{280834} proposed the
    progressive forest split scheme (PFS), in which several edge
    collapse operations are combined together and the inverse operation splits a
    forest of edges and vertices. 
    Payarola and Rossignac \cite{614450}, 
    proposed compressed progressive mesh (CPM)\label{cpm} with similar
    idea. They group about $50\%$ vertex splits into one batch. To
    differentiate vertices to be split with others, one bit per vertex
    is used as indicative. 
    Some more methods have the similar idea
    but based on vertex removal (remove a vertex and triangulates the hole
    generated) \cite{319358}. 

    More methods exist to reduce the cost in encoding connectivity information.
    Some of them are extended from the single rate coding algorithms
    \cite{319426, 383281}. Some extend progressive mesh to directly
    encode non-manifold meshes \cite{258852}.

    All compression methods introduced above 
    have a common drawbacks. After compression, the 
    data become linear and they have to be decoded in a fix order. 
    Therefore, these methods improve the coding efficiency at the cost
    of losing flexibility, which is essential in streaming of high-resolution
    progressive meshes.
    
    Flexibility of choosing streaming order 
    is restricted by the dependency among the vertex splits.
    For a manifold mesh, a vertex split operation depends on the existence of
    \begin{itemize}
        \item 
    the vertex to be split ($V_s$ in Figure \ref{dstream:split}), 
        \item 
    two cut neighbors ($V_l, V_r$ in Figure \ref{dstream:split}). 
    \end{itemize}
    More dependencies exist if artificial folds are strictly forbidden \cite{258843, 258847}, 
    but in this thesis we ignore these dependencies since we can 
    tolerate temporary folds in our scheme.
     
    To et al. \cite{To1999} further remove the second dependency.
    In their method, if a cut neighbor does not exist during a vertex split,
    its ancestor will be used as the cut neighbor instead.
    Kim and Lee \cite{kim01truly} improve this method so that the final mesh
    can keep the original connectivity. 
    Kim et al. \cite{multiresolution:kim} propose a better scheme that enables
    an ordinary progressive mesh to be split in random order.

    These methods increase the flexibility, however, have a low coding efficiency.
    One solution proposed by Yang et al. \cite{progressive:Yang}
    is to divide the whole mesh into several segments and encode them
    separately to trade off between flexibility and compression efficiency.
    The weakness is that the size of the base mesh is relatively large
    since the original vertices in the border of segments are kept in the base
    mesh. Furthermore, the quality of the base mesh is uneven.

    Kim et al. \cite{multiresolution:kim}
    have proposed compression algorithms that allow random splitting of a mesh without
    sacrificing compression efficiency. This method is neat since it achieves comparable
    efficiency with other compression methods but keeps the largest flexibility.
    This algorithm, however. are not designed for 
	network transmission.  We extend it in this thesis and more details are introduced
    in Chapter \ref{c:rdstream}.  
    \subsection{3D streaming}
    \label{ss:intro:streaming}
    Given the backgrounds in modeling and coding, now we introduce some
    related works in 3D streaming. 
    The main concern in 3D streaming is how to improve the quality of the received
    mesh as fast as possible. Current studies can be categorized to three groups
    by how to achieve this objective.
    %Three main classes of work exist 
    %-- error resilient streaming, packetization, and view-dependent streaming.
    
    \subsubsection{Error Resilient Streaming}
    To improve the quality quickly, we need to mitigate distortion to the 
    rendered quality of rendered mesh in the presence of packet losses.

    At the transport layer, Al-Regib and Altunbasak \cite{3tpregib}, Li
    et al. \cite{Li2006}, and Chen et al. \cite{chen05hybrid} have
    investigated how to intelligently select either TCP or UDP for
    transmissions to trade off reliability and end-to-end delay.  Li et
    al. have also considered SCTP with partial reliability.
    Harris III and Kravets \cite{harris:design} propose a new
    transport protocol that exploits loss tolerance and
    partially-ordered property of 3D objects organized into trees of
    bounding volumes.

    At the application layer, the major error control techniques: error
    resilient coding, error protection, retransmission, and error
    concealment \cite{Park2003}, have all been applied to mesh streaming.  
    %Park et al.
    %\cite{error:Park} and Yan et al. \cite{error:Yan} focus on how to best
    %segment a progressive mesh into smaller partitions such that it is
    %more resilient to losses.  Al-Regib et al. \cite{1061349} consider a
    %joint-source channel coding method to determine appropriate level of
    %error protection to use.  Chen et al. \cite{chen05hybrid} also use
    %FEC for transmission of 3D data.  Error concealment is considered by
    %Park et al. \cite{Park2003}.  
    %Cheng et al. \cite{cheng07analytical}
    %argue for retransmissions as the main error control method, while
    %Tian \cite{Tian2006} uses selective retransmission in their system.
    
    Existing work in robust mesh compression aims to
    reduce dependencies among the mesh \cite{error:Park,error:Yan}.
    Similar to introducing key frames or restart marker in video/image
    coding, mesh segmentation is used to reduce the affected range of one
    packet loss. In robust mesh compression, a mesh is typically
    divided into several independent parts and then coded separately.
    Therefore the effect of one packet loss is confined to the part to which
    it belongs. The finer the partition is, the fewer the affected vertices
    are.  The coding efficiency, however, will decrease
    due to more redundancies and less correlation.

    Al-Regib and Altunbasak \cite{unequal:Al-Regib} proposed an
    unequal error protection method to improve the resilience of
    progressive 3D mesh based on CPM (compressed progressive meshes). 
    Forward error correction (FEC) codes are added to the
    base mesh and additional levels-of-detail information to maximize 
    the decoded mesh quality.  The method is similar to FEC protection 
    of video data.

    Chen et al. \cite{chen05hybrid} also applied FEC to streaming
    progressive meshes. They analyzed several transmission schemes:
    TCP only, UDP only, TCP with UDP, and UDP with FEC, and studied
    their effects experimentally on the transmission time and decoded
    mesh quality.
    
    Some studies use retransmission to recover the packet loss.
    For example, Tian \cite{Tian2006} uses selective retransmission in their system.
    We think retransmission is more suitable than FEC when the feedback
    channel is available, because there is no playback deadline in streaming
    of 3D meshes and data is always useful.

    Most of methods introduced above treat the meshes streamed as 
    traditional linear data. When the flexibiliy of progressive mesh
    is considered, a new questions arises: how to select a sending order
    to improve the quality quickly and mitigate the effect of packet loss.
    We call it \emph{packetization} problem.
    
    \subsubsection{Packetization}
    \label{ss:intro:packetization}
    Packetization of different model is tackled by
    Harris III and Karvets in \cite{harris:design}.   
    They proposed a protocol named On-Demand Graphic Transport Protocol (OGP)
    for transmitting 3D models represented as a tree of bounding volumes.
    A key component of the protocol is to decide which bounding volumes
    to send.  OGP begins with packing the largest possible subtree at
    the root and continues to pack the nodes in the subtree of
    acknowledged nodes in breadth-first order.  
    
    Gu and Ooi \cite{Gu:Packetization} were the first to look at
    the packetization problem for progressive meshes.  They model
    the packetization problem as a graph problem where the objective
    is to equally partition the graph into $k$ partitions with minimum
    cut size.  The problem is shown to be NP-complete and a heuristic
    is proposed.  They, however, assume that every vertex split contributes 
    to the rendered quality equally.
    
    In practice, the contribution of vertex splits can
    vary considerably. Therefore, when choose sending order, we
    need to trade off between minimize the dependency and sending 
    vertex split has higher contribution first. To achieve this objective,
    the effect of dependency needs to be quantitatively measured.
    Before us, however, there is no study is done for this problem.

    A commonly used metric of contribution of vertex splits is 
    Hausdorff distance between the original and reconstructed mesh \cite{cignoni98metro}.
    As Hausdorff distance is view independent, 
    bandwidth may be wasted in sending invisible vertex splits
    before the visible ones. Moreover, even among the visible vertex splits,
    the view-independent metric cannot reflect the real contribution to the visual quality of
    clients with different viewpoints. A vertex split that significantly
    changes a mesh may change the rendered image 
    only slightly.  A better metric for visual contribution of a vertex split,
    based on the rendered image on the screen, 
    needs to consider the receiver's viewpoint.
    Streaming of 3D models based on this metric is named \emph{view-dependent} streaming.

    \subsubsection{View-Dependent Streaming}
    The view-dependent approach first appeared as 
    a dynamic simplification method used for adaptive rendering of a complex 3D mesh
    \cite{258843, 258847}. Only vertex splits that contribute to the rendered
    image will be rendered, allowing real-time rendering of a complex mesh
    even with limited rendering capability.
    Besides progressive mesh, other multi-resolution representations, 
    such as vertex-clustering  and subdivision scheme,
    are used in view-dependent refinement systems \cite{245627, efficient:Alliez,602344}.

    Later, the view-dependent approach is used in progressive 
	streaming of 3D meshes.     
    In the scheme proposed by Southern et al. \cite{363375},  the client is stateless and
    maintains only the visible data. 
    To et al. \cite{To1999}
    and Kim et al. \cite{kim:view} proposed that received data are stored
    in the receiver even after they become invisible, 
    so they need not be resent when they are visible again. 
    In these papers, view-dependent approaches mainly aim at addressing
    limited rendering capability. 
    
    Yang et al. \cite{progressive:Yang} and
    Zheng et al. \cite{zheng:interactive}, on the other hand, use
    view-dependent streaming to address limited network bandwidth.
    Yang et al. proposed a scheme where the server chooses the appropriate resolution
    according to the available network bandwidth.
    Zheng et al. \cite{zheng:interactive} use prediction to
    reduce the effect of network latency and 
    compensate the round-trip delay with the rendering time.
     
    These systems use sender-driven approach and do not address
    server scalability issues. Due to the stateful design, 
    the sender-driven approach is difficult to be extended to
    support caching proxy and peer-to-peer techniques, two 
    common solutions to scalability. Before us, there is no study about
    how to implement a scalable 
    view-dependent streaming system without incurring high infrastructural cost.

    In a view-dependent steaming system, the streaming order of data highly
    depends on the interactivity of users. Designing a satisfying system
    requires a understanding of user behaviors in viewing 3D meshes.
    Most previous work on user interactions with 3D objects focused on design
    of specific interaction techniques (e.g., the study by Chen et al. \cite{chen88study}
    and Hinckley et al. \cite{hinckley97usability}). 
    As far as we know, there is no studies before us which study user behavior
    from the system design point of view.
    
    %\section{Problem Statement}
    %\label{s:intro:problem}
    %(summary)
    %\begin{itemize}
    %    \item No quantitative analysis has been done for 
    %        finding the effect of dependency 
    %        when progressive meshes are transmitted over lossy networks. 
    %    \item Sender-driven view-dependent streaming
    %        is not scalable to large number of receivers. 
    %    \item No peer-to-peer system 
    %        exists for view-dependent progressive mesh streaming. 
    %\end{itemize}
    \section{Objectives and Scope}
    \label{s:intro:objectives}
    To address the gaps mentioned in Section \ref{ss:intro:streaming},  
    %To address the problems introduced in Section 1.5, 
    the objectives of this thesis are listed as follows: 
    \begin{enumerate}
        \item The first objective of this thesis is
            to quantitatively analyze how sending order affects
            the rendered quality of progressive meshes 
            during transmission over lossy network. 
            To achieve this objective, 
            an analytical model is proposed
            to estimate the decoding time of
            each vertex split by considering both
            the mesh property and network condition. 
            This model could help us to find some insights
            about the effect of dependency. 
            In addition, it may be applied to find a better sending strategy, 
            and a greedy strategy is given in the thesis as an example. 
            Compared with methods based on simulation, 
            analytical model is more efficient and may be used
            in the real time so that the sending order
            can be adaptive to the network condition.
        \item The second objective is to implement view-dependent streaming
            in a more scalable way. A receiver-driven approach is proposed 
            to move the visibility decision from the sender to the receiver.
            The receiver-driven approach increase the scalability
            %not only because it reduce  overhead of the sender 
            %but also 
            because it makes the caching proxy and peer-to-peer much easier
            to be applied to remove the bandwidth bottleneck on the sender side.
            The application of receiver-driven approach could eventually
            make possible the view-dependent streaming of large meshes
            to huge number of receivers.
        \item
            The third objective of this thesis is to study user behavior from 
            the system design point of view, such as predictability (for prefetching)
            and locality of access patterns (for caching), similar to the spirit
            of the landmark studies for the Web \cite{huberman98web} and file system
            \cite {ousterhout85trace}. Moreover, we could generate random user 
            behaviors similar to real ones and use them in simulations, which 
            are useful in testing protocols and measuring system performance.
        \item 
            The last objective is to examine the possibility 
            of implementing a peer-to-peer view-dependent streaming system. 
            The receiver-driven approach proposed in this thesis 
            makes the peer-to-peer system possible, 
            but due to the flexibility of data, some new challenges exist,
            such as chunking and content discovery. 
            The prototype proposed in this thesis could give some insights
            to the future research on this area. 
            Eventually, peer-to-peer system should be an attractive way 
            to bring the streaming of large meshes into practice. 
    \end{enumerate}

    Only streaming of static 3D objects is considered in this thesis. 
    Streaming of 3D animations beyonds the scope of this thesis. 
    Moreover, streaming of 3D scenes is not concerned in this thesis.
    Instead, this thesis concentrates on streaming of one large mesh.
    Nonetheless, streaming of 3D scenes becomes easier when mature methods
    of streaming of single objects exist because a 3D scene is the collection
    of multiple single meshes. 
    Finally, this thesis focuses on the streaming of progressive meshes. 
    Streaming of other representations of 3D objects is not discussed in this thesis,
    but the methods proposed in this thesis should be possible
    extended to support streaming of other representations with some modifications.

    Following four chapters will introduce how we achieve our objectives in detail.
    Chapter \ref{c:model} introduces our analytical model and its applications, and
    Chapter \ref{c:rdstream} describes our receiver-driven view-dependent streaming
    protocol in detail. The result of our user study and its analysis is introduced
    in Chapter \ref{c:user} and topics about implementing P2P mesh streaming systems
    are discussed in Chapter \ref{c:p2p}. Finally, the whole thesis is concluded in
    Chapter \ref{c:conclusion}.
\include{mesh}
\include{dstream}
\include{mm09-3dstreaming}
\include{p2p}

\chapter{Conclusion}
\label{c:conclusion}
This research concentrated on streaming of progressive meshes over network. 
First, the effect of dependency over lossy network was quantitatively analyzed. 
To enable quantitative analysis, an analytical model was developed to compute 
the probability distribution of the decoding time of each vertex split. 
Many experiments were carried out to verify the accuracy of the analytical model, 
and different network traces and progressive meshes were used to avoid bias. 
In these experiments, the predicted decoding time of vertex splits obtained 
with the analytical model was reasonably close to the measured one. 
Therefore, with the help of the analytical model, 
the quality of the received mesh could be predicted efficiently before transmission.
Consequently, adaptive transmitting vertex splits according to the network condition
becomes possible. Besides streaming of progressive meshes, 
streaming of other partially ordered data could also be modeled
with the analytical model in this thesis. 
For example, this model was successfully applied in streaming of 3D plants.

The analytical model in this thesis assumes that the packet losses 
are independent with each other, 
so a network trace with many burst packet losses may cause considerable error in the prediction. 
Gilbert model of packet loss may be used to obtain results that are more accurate, 
but using Gilbert model may significantly increase the complexity of the analytical model. 
Moreover, burst packet losses happen less commonly in the Internet
after widespread application of RED in routers. 
Therefore, the precision of the analytical model
without considering burst packet loss may be acceptable in most cases now.

It is observed in the experiments that the effect of dependency
is only significant in the short period at the beginning of transmission, 
and the length of this period increases
when the round trip time or packet loss rate increases. 
This observation is consistent with the result of the analytical model. 
Since each lost packet will be retransmitted as soon as the packet loss is detected, 
the effect of a packet loss is restricted to a certain period. 
This effect decreases with time because of two reasons. 
First, the contribution of the vertex splits sent decreases; 
second, the quality of the reconstructed mesh increases. 
Consequently, the relative value of the effect, 
represented as the ratio of the contribution of vertex
splits to the quality of the reconstructed mesh, decreases.
As a result, considering the dependency among the vertex splits 
is only needed for applications requiring high interactivity
because these applications require low initial latency. 
For these applications, the greedy method proposed in this thesis
could generate a adaptive sending strategy to reduce the initial latency. 

View-dependent streaming is needed in streaming of large meshes
to improve the quality quickly, but current implementations cannot be easily scaled
to large number of receivers because the sender is not stateless. 
To address this weakness, a receiver-driven view-dependent streaming system,
in which the sender is stateless, was proposed in this thesis. 
According to the experimental results, the receiver-driven approach
can reduce both the CPU usage and outgoing bandwidth of the sender significantly. 
Moving the visibility decision to the receiver reduces the overhead of the server. 
Moreover, it also reduces the outgoing bandwidth of the sender because the server
does not need to send the identifications of the vertex splits any more. 
Above all, a significant advantage of receiver-driven approach is that
now both the caching proxy and P2P techniques can be applied to increase the scalability of the system
because of the sender is stateless. 

The visibility decision made by the receiver may not be accurate 
because the receiver can only estimate the visibility based on
the partially received mesh. 
Visible vertices may be not displayed if their ancestor vertices are not visible. 
According to the current results, however, this kind of error is negligible in most cases. 
For applications that tolerate no error, 
further research could be done to remove this kind of error. 
A possible solution could be to split those vertices near the silhouette even when they are invisible.

To increase the scalability of the view-dependent mesh-streaming systems, 
a P2P mesh streaming system was proposed in this thesis based on the receiver-driven approach. 
According to the experimental results, the server overhead can be reduced by 90\%
and the response time is still close to the low bound. 
The control overhead introduced in this system is about 10\%, a reasonable value. 
The response time is low because most requests in this system are successful in the first try, 
and the message overhead is reasonable because the hierarchical group system proposed in this thesis effectively 
reduces the message overhead. 
The prototype developed in this thesis shows that P2P mesh streaming system is feasible
and it can significantly reduce the server cost when there are many clients.

The control overhead at 10\% is acceptable in this system since the majority of
control messages are transmitted among the peers and the server overhead keeps low. 
Nonetheless, the message overhead could be further reduced. 

During the study, it is found that in some cases the bottleneck can be the rendering of the meshes, 
especially when the graphic card is used in deciding the visibility of vertices. 
Improving the rendering efficiency of the progressive mesh during the streaming 
could be an interesting research problem.  
During the streaming, a progressive mesh with only partial modification is frequently re-rendered, 
so it is possible to exploit the similarity between two consecutive meshes to improve the rendering speed.
\bibliographystyle{abbrv}
\bibliography{thesis}
\end{document}
