\documentclass[11pt, a4paper]{report}
\clubpenalty=10000
\widowpenalty=10000
\usepackage{fullpage}
\usepackage{epsfig}
\usepackage{setspace}
\usepackage{latexsym}
\usepackage{algorithmic}
\usepackage{algorithm}
\usepackage{epsfig}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{subfigure}
\usepackage[usenames]{color}
\usepackage{verbatim}

\newcommand\todo[1]{\textcolor{Red}{\textbf{#1}}}
\newcommand\pOlost{\textrm{$P_0$ is lost}}
\newcommand\QED{\hfill\ensuremath{\Box}}
\let\showproof1


\newtheorem{lemma}{Lemma}
\newtheorem{theorem}{Theorem}
\newenvironment{proof}[1][Proof]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}


\title{Streaming of High-Resolution Progressive Meshes Over Network}
\author{Wei CHENG\\
National University of Singapore\\
\\
\\
SuperVisor\\
Wei Tsang OOI}
\begin{document}
\maketitle
\doublespacing
\begin{abstract}
    \begin{comment}
    High-resolution 3D meshes are increasingly available in networked
    applications, such as digital museum, online game, and virtual reality.
    The amount of data constituting a high-resolution 3D mesh can be
    huge, leading to a long downloading time. 
    To reduce the waiting time of users, 
    a common technique for remote viewing is progressive streaming,
    which allows a low-resolution version of the mesh to be transmitted
    and rendered with low latency. Then the quality of the transmitted 
    mesh can be incrementally improved when the refinement information
    is continuously being transmitted.

    Progressive mesh is commonly used to support progressive
    streaming. A progressive mesh comprises a \emph{base mesh} and a series
    of refinements. The base mesh is obtained by simplifying the original mesh
    with a series of \emph{edge collapses}.
    With the \emph{vertex splits}, the inverses of these edge
    collapses, the original mesh can be reconstructed from the base mesh.
    Therefore, progressive streaming can be implemented by sending the vertex
    splits as refinements after sending the base mesh.

    Although streaming of videos is extensively studied, 
    streaming of high-resolution progressive meshes is considerably different.
    Frames of a video are usually sent following the time order,
    vertex splits of a progressive mesh, however, can be sent in various of orders.
    Some new research problems arise due to the flexibility in sending order of 
    vertex splits. In this thesis, four related topics are discussed. 
    %After decoding, each frame contributes the same to a video, but vertex splits
    %in a progressive mesh vary considerably in their contribution to the quality
    %of the reconstructed mesh. 
       
    First, 
    %the effect of dependency needs to be considered in choosing
    %the sending order of vertex splits.
    the progressive coding of meshes introduces dependencies among 
    the vertex splits, and the descendants cannot be decoded
    before their ancestors are all decoded. Therefore, 
    when a progressive mesh is transmitted over a lossy network,
    a packet loss will delay the decoding of the following
    vertex splits if they depend on this lost packet. 
    %These successfully received vertex splits cannot be 
    %decoded until the lost packet is successfully retransmitted. 
    Hence, the effect of dependency needs to
    be considered in choosing the sending order of vertex splits. 
    %To find the effect of dependency
    %is non-trivial as the packet loss happens randomly.
    In this thesis, an analytical model is proposed to 
    %quantify the effect of dependency on the quality curve.
    quantitatively analyzes the effects of dependency
    by modeling the distribution of decoding time of each vertex split
    as a function of mesh properties and network parameters.
    %The quality curve is determined by the decoding time of the vertex
    %splits and their contributions to the overall mesh quality.    
    %The decoding time of a vertex split depends on its receiving time and the 
    %receiving time of its all ancestors. The receiving time of a vertex split
    %in turn depends on its sending time and how many times it is 
    %transmitted. 
    %Hence, the distribution of decoding time of each vertex split
    %is modeled as a function of the mesh property and the network condition.
    %From this expression, %both the expected value and 
    %the distribution of the decoding time of each
    %vertex split can be efficiently computed before transmission. 
    Consequently, Different sending orders can be  
    efficiently evaluated without simulations, 
    and this model can help in developing a sending
    strategy to improve the quality curve 
    during transmission. % to improve the quality.
    
    Furthermore, %closed-form expressions are derived in two extreme cases,
    this model is applied to study two extreme cases of dependency in 
    progressive meshes and
    %providing insights to the importance of dependencies on the
    %decoded mesh quality. 
    The main insight found is that if each lost packet
    is immediately retransmitted upon the packet loss is detected, 
    the effect of dependencies on decoded mesh quality diminishes with time.
    %the dependencies only matters in the first several round trip times. 
    Therefore, the effect of dependency is only significant in the applications
    requiring high interactivity. 

    The accuracy of the analylitical model proposed in this thesis is validated
    under a variety of network conditions, including bursty losses, fluctuating RTT,
    and varying sending rate. The values predicted from our model match the measured
    value reasonably well in all cases except when losses are too bursty.
    
    To further improve the quality curve, the view-point of the 
    user can be considered in deciding the sending order.
    %Usually, users can only see a part of a mesh, so sending non-visible data
    %before visible data wastes bandwidth. Moreover, 
    Non-visible vertex splits do not need to be sent, and 
    the visual contributions of visible vertex splits (how much they can improve the rendered image)
    also depend on the view-point of the user.
    Hence, choosing the sending order according to the viewpoint of the user, so called
    \emph{view-dependent streaming}, is a natural choice.
    
    In existing solutions to view-dependent streaming,  the
    sender decides the sending order. 
    %This sender-driven protocol has several
    %drawbacks. First, it is not scalable to many receivers as the sender has to
    %determine the visibility of vertices and sort the visible vertex splits based on their
    %visual contributions for each receiver. 
    %Second, 
    The sender needs to maintain
    the rendering state of each receiver to avoid sending duplicate data. 
    Due to the stateful design %and high computational requirements,
    the sender-driven approach cannot be easily extended to support 
    many receivers with caching proxy and peer-to-peer system,
    two common solutions to scalability. 

    In this thesis, a receiver-driven protocol is proposed to 
    improve the scalability. In this protocol, the receiver decides the sending order
    and explicitly requests the vertex splits, 
    while the sender simply sends the data requested.
    The sending order is computed at the receiver  by estimating the visibility
    and visual contributions of the refinements, even before receiving them,
    with the help of GPU.

    Because the visibility determination and state maintenance are all done by the receivers, 
    the sender in our receiver-driven protocol is stateless and free of complex computation.
    Furthermore, caching proxy and P2P streaming systems can be applied to improve
    the scalability without adding more servers.  
    
    The receiver-driven protocol significantly reduces the computing cost at the sender,
    but the bandwidth can remain the bottleneck if each receiver receives data
    from the same sender. 
    Based on the receiver-driven protocol, P2P techniques are applied to mesh
    streaming in this thesis. In the implementation of P2P mesh streaming system,
    two issues are considered: how to partition a progressive mesh into chunks and 
    how to lookup the provider of a chunk. For the latter issus, we investigated 
    into two solutions, which trade off server overhead and response time. The first
    uses a simple centralized lookup service, while the second organizes peers into
    groups according to the hierarchical structure of the progressive mesh to 
    take advantage of access pattern. Simulation results show that our 
    proposed systems are robust under high churn rate, reduce the server overhead
    by more than $90\%$, keep control overhead below $10\%s$, and achieve
    low average response time.
\end{comment}
\end{abstract}
\chapter{Introduction}
\label{c:intro}
    Advances in 3D scanning technology and 3D modeling
    techniques have lowered the barrier in creating
    high-resolution 3D models.  
    First, high-resolution 3D models can be created
    with laser scanner and reconstruction softwares.
    For example, the Stanford's Digital Michelangelo Project
    has digitalized several famous statues of Michelangelo
    \cite{levoy00digital} (See Figure \ref{f:intro:scanner}. 
    Similar projects include 
\begin{figure}[htbp!]
\centering
\epsfig{file=scanner.eps, height=0.3\textwidth}
\caption{Stanford's Digital Michelangelo Project. The head of David Statue is being scanned.}\label{f:intro:scanner}
\end{figure}
    the Digital Sculpture Project \cite{deroos2004dsp}
    and the project to digitize Rodin's sculptures \cite{miyazaki2006dab}. 
    Second, artists can directly create high-resolution 3D models with
    digital sculpture softwares such as ZBrush (See Figure \ref{f:intro:zbrush}).
\begin{figure}[htbp!]
\centering
\begin{tabular}{cc}
\epsfig{file=zbrush1.eps, height=0.3\textwidth}
&
\epsfig{file=zbrush2.eps, height=0.3\textwidth}
\end{tabular}
\caption{Complex digital sculptures created with ZBrush.}\label{f:intro:zbrush}
\end{figure}

    Sharing high-resolution 3D models over network is useful in many
    applications. Digital museum exhibiting 3D models of artifacts
    is an example. 
    Exhibiting high-resolution 3D models of artifacts instead of the
    artifacts themselves has many advantages. 
    People can view the artifacts from
    anywhere, at anytime, and without any travel cost. 
    Visitors can interact with exhibited artifacts
    in any way they want, without worrying about damaging them 
    or interfering other visitors. 
    Moreover, the museum can exhibit artifacts, however precious they are, 
    safely without worrying about corrosion and stealing.

    High-resolution 3D models are useful in other networked applications too. 
    For example, virtual world applications,
    such as Second Life, may become more realistic and interesting by
    supporting high-resolution 3D models. 
    Commercial users could show their products as 3D models to potential users all over 
    the world. Sculptors could demonstrate their artworks freely without renting an gallery.
    As another example, Virtual Earth applications, 
    such as Google Earth, could represent many landmark buildings or statues
    (e.g. Statue of Liberty) as high-resolution 3D models to serve
    the visitors better.

    When used in networked applications, 
    high resolution 3D models may take long time to download completely
    for display at the client. 
    For example, the Stanford model of the David statue, with 28 million vertices and
    56 million triangles, is still 70 MB in size with
    state-of-the-art compression \cite{alliez2001progressive} and needs around 10 minutes
    to download at 1 Mbps.  
    To reduce the waiting time of the user, 
    the streaming technology can be used to transmit 3D models. 
    The 3D streaming technology enables users to render the partially received data as a preview, 
    and then improve the quality when more data are available. 
    Users can decide how many data to receive based on their requirement of quality
    and the rendering ability of their hardware.

\begin{figure}[htbp!]
\centering
\epsfig{file=split2.eps, width=0.5\textwidth}
\caption{Edge collapse and vertex split}\label{f:intro:split2}
\end{figure}
    One popular representation to support 3D streaming, progressive mesh, 
    is proposed by Hoppe \cite{hoppe96progressive}.
    The technique is based on an
    operation called \textit{edge collapse}, and its reverse
    operation, \textit{vertex split}.  Given a (non-progressive)
    3D mesh, the technique applies a series of edge collapses,
    simplifying the model by reducing the number of vertices and
    faces.  The final, simplified model obtained after this
    process becomes the \textit{base model}.  Given a base model,
    we can reconstruct the original model by reversing
    the edge collapse operations through \textit{vertex splits},
    incrementally adding new vertices and faces. So, a
    progressive mesh can be represented by the base
    model and a series of vertex splits.  
    Figure~\ref{f:intro:split2} illustrates edge
    collapse and vertex split operations.
    Progressive streaming can be implemented by sending the base mesh
    first as a preview and then sending vertex splits to improve 
    the quality incrementally (See Figure \ref{f:intro:progressive}).
    \begin{figure}[htbp!]
    \centering
    \epsfig{file=progressive.eps, width=0.6\textwidth}
    \caption{
    Progressive 3D mesh streaming. The original Happy Buddha mesh 
    courtesy of Stanford Computer Graphics Laboratory.
    \label{f:intro:progressive}}
    \end{figure}
    
    Although audio and video streaming have been studied extensively, 
    3D streaming remains a new research topic. 
    Video streaming and 3D streaming are significantly different
    due to the difference between videos and 3D models, and
    the main difference is how users consume the data.
    In video streaming, usually the data are consumed in time order. 
    Whereas in 3D streaming, especially when high-resolution 3D models are used,
    users may consume different subset of the data, and in various orders.
    
    Concequently, flexibility in choosing sending order and sending subset 
    in 3D streaming.
    This flexibility is important in streaming of high-resolution 3D models, 
    because streaming a huge 3D model in a fix order may waste much time and bandwidth in 
    transmitting data not useful to the user. 
    To ensure this flexibility in streaming system is an important consideration
    in choosing representation and coding schemes, and details are discussed
    in Chapter \ref{c:related}.
    Meanwhile, this flexibility introduces some new research questions, 
    which are introduced in next section. 

  \section{Research Objectives and Scope}
  \label{s:intro:objectives}
    \subsection{Quantitatively Determining the Effect of Dependency}
    In progressive streaming, the quality of the mesh on the receiver
    increases over time.
    Because vertex splits contribute differently to the quality, 
    how quality improves
    depends on the decoding order of the vertex splits,
    which in turn depends on the sending order of the vertex splits.
    Because of the flexibility existed in choosing sending order,
    it is possible to choose a sending order so that the 
    quality on the receiver increases as fast as possible.

    A natural method is to send vertex splits in the descending order
    of their contribution to the quality of the received mesh. 
    This strategy, however, is not always optimal, 
    because dependency also plays an important role
    when the mesh is transmitted over a lossy network.
    
    The progressive coding of meshes introduces dependencies among 
    the vertex splits, and the descendants cannot be decoded
    before their ancestors are all decoded. Therefore, 
    when a progressive mesh is transmitted over a lossy network,
    a packet loss will disable the decoding of the following
    vertex splits if they depend on this lost packet. 
    These successfully received vertex splits cannot be 
    decoded until the lost packet is successfully retransmitted. 
    Hence, another consideration in choosing sending order
    is to minimize the dependency among packets so that most
    received vertex splits can be decoded without waiting.
    
    To find a proper trade-off between sending most important vertex
    split first and to minimize the dependency among packets, we 
    need to quantitatively know the effect of dependency. This task
    is non-trivial as this effect depends on both network condition (random
    packet losses) and the property of meshes (dependency among vertex splits).
    Therefore, the first research objective in this thesis is
    \begin{itemize}
        \item
            to quantitatively analyze the effect of dependency on 
            the rendered quality of progressive meshes 
            during transmission over lossy network, and to find
            a proper sending order to improve the quality as quick
            as possible, considering both the mesh property and network condition. 
    \end{itemize}
    
    \subsection{Receiver-Driven View-Dependent Streaming System of Progressive Meshes}
    Another factor, the viewpoint of the user, 
    needs to be considered in deciding the sending order of vertex splits.
    Sending non-visible data before visible data wastes bandwidth. 
    Moreover, the visual contributions of visible
    vertex splits (how much they can improve the rendered image)
    also depend on the view-point of the user.
    Hence, choosing the sending order and sending subset 
    according to the viewpoint of the user, 
    so called \emph{view-dependent streaming}, 
    is a natural choice, especially
    for high-resolution meshes.
    
    In existing solutions to view-dependent streaming,  
    the sender decides the sending order. 
    This sender-driven protocol has several drawbacks. 
    First, it is not scalable to many receivers as the sender has to
    determine the visibility of vertices for each receiver. 
    Second, the sender needs to maintain
    the state of each receiver to avoid sending duplicate data. 
    Due to the stateful design and high computational requirements,
    the sender-driven approach cannot be easily extended to support 
    many receivers with caching proxy and peer-to-peer system,
    two common solutions to scalability. 

    Therefore, the second objective in this thesis is 
    \begin{itemize}
        \item
            to implement 
            a receiver-driven view-dependent streaming system, where
            the visibility decision is done by the receiver instead of the sender,
            to make the sender stateless.
            Then caching proxy and peer-to-peer techniques can be used to increase the 
            scalability of the progressive mesh streaming system.
    \end{itemize}

    \subsection{Patterns of User Behaviors in viewing 3D Meshes}
    In a view-dependent steaming system, the sending order and sending subset 
    of data highly depends on the interactivity of users. 
    Designing a satisfying system
    requires a understanding of user behaviors in viewing 3D meshes.
    For example, if user actions are somewhat predictable, pre-fetching can 
    be used to reduce the response time. If we know in advance that some parts
    of a huge mesh are requested most frequently, they can be 
    cached to significantly reduce server overhead.
    
    Most previous work on user interactions with 3D objects focused on design
    of specific interaction techniques (e.g., the study by Chen et al. \cite{chen88study}
    and Hinckley et al. \cite{hinckley97usability}). 
    As far as we know, there is no studies before us which study user behavior
    from the system design point of view.
    Therefore, the third objective of this thesis is 
    \begin{itemize}
        \item
            to study user behavior from 
            the system design point of view, such as predictability (for prefetching)
            and locality of access patterns (for caching), similar to the spirit
            of the landmark studies for the Web \cite{huberman98web} and file system
            \cite {ousterhout85trace}. 
    \end{itemize}

    \subsection{P2P View-Dependent Progressive Mesh Streaming System}
    The receiver-driven protocol significantly reduces the computing cost at the sender,
    but the bandwidth can remain the bottleneck if each receiver receives data
    from the same sender and the number of receivers becomes large. 
    Peer-to-peer (P2P) technique is a common solution to increase
    the scalability without incurring high infrastructural cost. 
    Applying the P2P technique into progressive mesh streaming system
    is considerably simplified by our receiver-driven protocol since 
    the sender is stateless and free of expensive computations.
    Whereas, the implementation is still challenging because the flexibility
    of choosing the sending order and sending subset.
    
    In P2P mesh streaming, users 
    may choose to look at different facets, or zoom into different level.
    Therefore, each peer may choose a unique sending order of
    vertex splits. Hence, how to group vertex splits into chunks is not
    straightforward. Moreover, since peers may have different subsets of the
    mesh, it is difficult for a peer to keep receiving
    needed data from another peer for a long time, and  
    a peer would have to continuously look for peers to retrieve the mesh data from, 
    which makes content discovery more challenging.

    Hence, the last objective of this thesis is 
    \begin{itemize}
        \item
            to solve chunking and content discovery problems introduced by 
            the flexibility in choosing sending order and sending subset, and
            to implement a prototype of P2P view-dependent mesh streaming system
            based on the receiver-driven protocol proposed in this thesis.
    \end{itemize}
    
    \subsection{Scope}
    Only streaming of static 3D objects is considered in this thesis. 
    Streaming of 3D animations beyonds the scope of this thesis. 
    Moreover, streaming of 3D scenes is not concerned in this thesis.
    Instead, this thesis concentrates on streaming of one large mesh.
    Nonetheless, streaming of 3D scenes becomes easier when mature methods
    of streaming of single objects exist because a 3D scene is the collection
    of multiple single meshes.
    Finally, this thesis focuses on the streaming of progressive meshes. 
    Streaming of other representations of 3D objects is not discussed in this thesis,
    but the methods proposed in this thesis should be possible
    extended to support streaming of other representations with some modifications.
    
  \section{Contributions}
  \label{s:intro:objectives}
    In this section, We introduce the contributions of this thesis by
    summarizing how we achieve the objectives introduced in 
    Section \ref{s:intro:objectives} and their significances.
    
    \subsection{Objective 1}
    \begin{itemize}
        \item
            To quantitatively analyze the effect of dependency on 
            the rendered quality of progressive meshes 
            during transmission over lossy network, and to find
            a proper sending order to improve the quality as quick
            as possible, considering both the mesh property and network condition. 
    \end{itemize}
            
    To achieve this objective, an analytical model is proposed
    to estimate the decoding time of each vertex split by considering both
    the mesh property and network condition. 
    From this model, we can efficiently know both the expected 
    value and the distribution of the decoding time of each
    vertex split before transmission. Consequently, 
    we can analytically evaluate different sending orders without simulations.
    
    Moreover, our model can help in developing a sending
    strategy to improve the quality as soon as possible,
    and a greedy strategy is given in the thesis as an example. 
    Further, we derive closed-form expressions in two extreme cases,
    providing insights to the importance of dependencies on the
    decoded mesh quality. The main insight is that if each lost packet
    is immediately retransmitted upon the packet loss is detected, 
    then the dependencies only matters in the first several round trip times. 
    Therefore, the effect of dependency is only significant in the applications
    requiring high interactivity. 

    To show that the insights from the theoretical model can be applied
    in practice, we extensively verified our model under different conditions,
    using different progressive meshes, network conditions, and quality metrics. 
    The experimental results show that our model works well under realistic 
    conditions despite the simplification and assumptions we made during
    modeling.

    Our analytical model is general and can be applied to any 
    partially-ordered data without playback deadline.
    Examples of such partially-ordered data include point-based models 
    organized as QSplat trees \cite{rusinkiewicz:qsplat} and digitized plants.  
    We have actually applied our analytical model to the latter \cite{plant:seb}.
    
    \subsection{Objective 2}
    \begin{itemize}
        \item
            To implement 
            a receiver-driven view-dependent streaming system, where
            the visibility decision is done by the receiver instead of the sender,
            to make the sender stateless.
            Then caching proxy and peer-to-peer techniques can be used to increase the 
            scalability of the progressive mesh streaming system.
    \end{itemize}
    
    In implementing the receiver-driven protocol, we solved three main problems.
    First, the receiver has to decide the visual contribution 
    of a vertex split before receiving it.
    Second, the receiver needs to know the unique ID
    (identification number) of each vertex so that it
    can explicitly request data to split it. 
    We avoid explicitly including the IDs in the vertex splits,
    as it will significantly increase the data size.
    Third, the vertex splits need to be efficiently compressed without
    sacrificing the flexibility in choosing sending order.
    
    For the first problem, we find that although it is difficult
    for the receiver to accurately measure
    the visual importance of a vertex split before receiving it, 
    estimation suffices in our scheme. 
    We proposed two estimation methods and compared them with experiments.
    
    To uniquely identify each vertex, we borrow the idea from Kim and Lee \cite{kim01truly}.
    In this system, IDs can be deduced by the receiver without any extra information. 
    We also adapted and extended the compression algorithm proposed by Kim et al. \cite{multiresolution:kim}
    to achieve the comparable compression ration with high flexibility in choosing 
    sending order.
    
    Then, based on these solutions, we implement a receiver-driven protocol in which 
    the visibility determination and state maintenance are all done by the receivers, so 
    the sender in our receiver-driven protocol is stateless and free of complex computation.
    Hence, caching proxy and P2P streaming systems can be applied to improve
    the scalability without adding more servers.  
    Therefore, the receiver-driven approach may eventually
    make possible the view-dependent streaming of high-resolution meshes to huge number of receivers.
    
    \subsection{Objective 3}
    \begin{itemize}
        \item
            to study user behavior from 
            the system design point of view, such as predictability (for prefetching)
            and locality of access patterns (for caching), similar to the spirit
            of the landmark studies for the Web \cite{huberman98web} and file system
            \cite {ousterhout85trace}. 
    \end{itemize}

We conducted a user experiment with 37 users interacting with 9 meshes.
We log the user's actions while they interact and view the meshes in a mock online shop.
Then we analyze these traces to derive the patterns of user behaviors.

The contributions of our user study are:
First, the analysis of user traces reveals that 
        user actions are predictable to certain extent. 
        Hence, pre-fetching based on our analysis becomes possible.
        Second, 
        locality exists in both data and viewpoint access. By
        storing the most popular mesh data in caching proxies, 
        the server overhead could be significantly reduced. 
        Moreover, caching rendered images can be useful in remote rendering,
        and caching faces and textures is useful in improving rendering speed.
        Finally,
        We develop a method to generate random user behaviors similar to real ones
        and use them in simulations, 
        which are useful in testing protocols and measuring system performance.

    \subsection{Objective 4}
    \begin{itemize}
        \item
            to implement a prototype of P2P view-dependent mesh streaming system
            based on the receiver-driven protocol proposed in this thesis.
            The emphasis is to solve chunking and content discovery problems. 
    \end{itemize}
    
    Before implementing the system, 
    we compare and contrast P2P mesh streaming to P2P
    video streaming and P2P file downloading and point out
    the main difficulties of P2P mesh streaming:  
    chunking and content discovery.

    We propose a chunking scheme by exploiting the hierarchical 
    nature of the data. It suits for mesh streaming very well.
    First, the receiver can know which vertex split belongs to
    which chunk implicitly without extra data embedded in the stream.
    Second, vertex splits in a chunk are close to each other so
    their visibility are similar. Third, the dependency among chunks
    are minimized.

    We investigate on two content discovery schemes for P2P
    mesh streaming: centralized lookup and hierarchical P2P lookup.
    The first design is easy to implement and works will in small to 
    middle scale network. The structure of the progressive
    mesh is considered in the second design to further
    reduce server overhead, so it is more suitable for large scale networks. 
    
    Finally, we run simulations based on real
    traces collected from users to evaluate the P2P
    mesh streaming system we proposed.  Analysis and
    simulation results show that server overhead can be
    reduced by 90\%. Meanwhile,  average response time and
    control overhead are low.

    Our results indicate that with the help of P2P technique,
    sharing high-resolution
    3D models to a large number of users over network is affordable
    to small companies, and even single persons. We believe this is
    essential for networked applications using high-resolution 3D models
    become popular.

    In next chapter, we will introduce some backgrounds and related works.
    The following four chapters will introduce how we achieve our objectives in detail.
    Chapter \ref{c:model} introduces our analytical model and its applications, and
    Chapter \ref{c:rdstream} describes our receiver-driven view-dependent streaming
    protocol in detail. The result of our user study and its analysis is introduced
    in Chapter \ref{c:user} and topics about implementing P2P mesh streaming systems
    are discussed in Chapter \ref{c:p2p}. Finally, the whole thesis is concluded in
    Chapter \ref{c:conclusion}.

\chapter{Backgrounds and Related Works}
\label{c:related}
    \section{Representation}
    \label{s:related:representation}
    A 3D object is represented with a certain model.
    Currently the most popular representation of 3D objects is polygonal meshes, 
    especially the triangle meshes, because most graphic cards are optimized for triangle meshes. 

    A triangle mesh can be donated as a tuple $(K, V)$, where $K$ is a
    \emph{simplicial complex} including all the mesh simplices 
    (vertices, edges and triangles) and $V =\{v_{1}, v_{2}, ...,
    v_{n}\}$ is the set of geometry positions of vertices. Therefore,
    a mesh has both \emph{connectivity} information represented by $K$
    and \emph{geometry information} represented by $V$. In another
    word, $K$ includes all the topology information of all the
    elements in the mesh, and with $V$ it is embedded into $R^{3}$. If
    polygons are allowed in $K$ instead of only triangles, then this
    kind of meshes are called polygonal meshes.

    In a mesh, it is required that every
    vertex is an end of an edge and every edge should be incident to at
    least one face ((a) in figure \ref{mesh_non_mesh} is not a mesh).
    The number of edges incident to a vertex is called the
    \emph{valence} of this vertex, and the number of edges incident to
    a face is called the \emph{degree} of this face. An edge only
    incident to one face is called a \emph{boundary edge}; an edge
    shared by two faces is called an \emph{interior edge}; an edge
    shared by more than two faces is called a \emph{singular edge}. A
    \emph{manifold mesh} is a mesh without singular edges and every
    two faces share one edge or nothing (see figure \ref{mesh_non_mesh}).
\begin{figure}
\centering
\includegraphics[width=0.8\textwidth]{figure2.1.eps}
\caption[Manifold mesh, non-manifold mesh and non-mesh]{ (a) is not
a mesh since one edge is incident to no face. (b) is a manifold
mesh. (c) is a non-manifold mesh since there is a singular edge.
(d) is a non-manifold mesh since two faces share only a
vertex.\label{mesh_non_mesh}}\
\end{figure}

    Polygonal meshes can be used as an approximation of the surfaces
    of 3D objects. In this case, some properties of the surface such
    as color and normal are often associated to the mesh. These
    properties can be categorized into two types: discrete attributes
    and scalar attributes \label{property}. Discrete attributes, such
    as material identifier, are usually associated to the faces, while
    scalar attributes, such as color, normal, and texture coordinate,
    are often associated to vertices or corners (the tuple (vertex,
    face)). The latter one is used because in the case of
    discontinuity, a vertex can have more than one scalar value. For
    example, if two smooth surface intersect at a curve, then vertices
    in this curve will have two different normal values. Therefore,
    the normal value should be associated to the tuple (vertex face).
    Then, polygonal meshes can be represented by $(K, V, D, S)$ where
    $D$ is the set of discrete attributes associated to face $f \in
    K$ and $S$ is the set of scalar attributes associated to corners $(v, f)$ in $S$.
    
    Besides meshes, point-based representations are also used in the practice.
    A point-based geometry representation can be considered as a 
    sampling of a continuous surface.  The result are a set of 3D points. 
    %These points are optionally associated with the normal vectors 
    %and other attributes, such as color and material properties. 
    To bridge the gaps between neighboring point samples, 
    bounding spheres \cite{rusinkiewicz:qsplat, 364350} or surface splats \cite{383300} are used as rendering primitives. 
    More details about point based model can be seen in the survey by Kobbelt and Botsch \cite{DBLP:journals/cg/KobbeltB04} 
    and the PhD thesis of Wand \cite{wand:point}.  
    
    Moreover, some other representations also exist, such as simple solid models used in Second Life
    and generalized cylinders used in representing plants \cite{plant:seb, compact:mondet}.

    %\subsection{Choice in This Thesis}
    This thesis concentrates on meshes because of following reasons:
    \begin{itemize}
        \item Most rendering hardwares are optimized for meshes, so other model need to be convert
            to mesh before rendering either explicitly or implicitly. 
        \item Without connectivity information in the model, point-based model is relatively easier to deal with
            than meshes. Therefore, adapting techniques used in streaming meshes to streaming point-based model
            is easier than the opposite direction.
    \end{itemize}

    \section{Coding and Compression}
    A mesh is encoded first before it can be stored or
    transmitted. Coding is to represent a mesh with a sequence of
    digits. Compression is always combined with coding to save the storage space
    or the bandwidth needed in transmission. 
    There are two kinds of coding:
    single-rate coding and progressive coding. 
    Single-rate coded mesh can only be decoded when all data are available 
    whereas progressive coded mesh can be decoded with only part of data are available. 
    We will briefly introduce single-rate coding methods, and then concentrate on
    progressive coding methods, because the latter are more suitable for progressive streaming.
    
    \subsection{Single-rate Coding} \label{single_rate}
    In a mesh, three kind of information needs to be coded:
    connectivity, geometry and property. 
    Since most property data are associated to vertices, 
    in many compress algorithms they are treated as same as geometry data or even
    ignored. We introduce connectivity coding first, and then introduce geometry coding briefly.
    
    A triangle mesh is often represented as an array of vertex coordinates
    (geometry information) and an array of triangles (connectivity information). 
    A triangle is represented by the indices of its three vertices.
    In this representation, every vertex is indexed by all the
    triangles to which it is incident. Repeated references introduce
    redundancy. Therefore, triangle strip method is introduced to
    reduce this redundancy. In a triangle strip, a triangle fan, or a
    generalized triangle strip (a mixture of triangle strips and
    triangle fans) (see Figure \ref{strip}), 
    triangles can be represented with one index of vertex
    except the first triangle. 
    Deering \cite{218391} first introduced generalized triangular mesh, 
    which combining the generalized triangle strips with a vertex buffer,
    which is used to further reduce the bits used to represent indices. 
    Furthermore, Chow \cite{267103} introduced a method to
    decompose a mesh into triangle strips. 
    Bajaj, Pascucci and Zhuang \cite{789628} presented a coding method with layered
    decomposition. 
    Typically, a triangle layer is a generalized triangle strip. 
    \begin{figure}[ht]
    \centering
    \includegraphics[width=0.6\textwidth]{strip.eps}
    \caption{(A)The triangle strip, (B)the triangle fan, and (C) the generated triangle strip.}\label{strip}
    \end{figure}

    Taubin and Rossignac \cite{274365} proposed a method named
    \emph{topological surgery}, which changes coding of a manifold
    mesh to coding of two trees: a vertex spanning tree and the dual of the triangles.
    Topological surgery has been implemented in MPEG-4 standard, and more details
    can be seen in the report of Taubin\cite{3d:Taubin}.
    
    Touma and Gotsman \cite{triangle:Touma} introduced a
    valence-driven approach to encode the connectivity by coding the
    valence of all the vertices in a specific traversing order. 
    The performance is further improved
    by Alliez and Desbrun \cite{alliez01valencedriven}, who also proved a
    upper-bound 3.24 bpv, exactly the theoretical value computed
    by Tutte \cite{census:Tutte} after enumerating all possible planar
    graphs.

    Several methods based on triangle conquest have also been
    proposed, such as \emph{cut-border machine} proposed by 
    Gumhold and Stra\ss{}er \cite{280836}.
    A significant advantage of this method is that it can be easily implemented
    in hardware and the decompression is very fast, which
    renders it to be very useful in real-time coding. 
    Another method named \emph{edgebreaker} is presented by Rossignac \cite{614421},
    and it is similar to the cut-border machine but has better
    compress efficiency and much slower decompression speed.
    
    After introduction of connectivity coding, we briefly introduce geometry
    coding. Most single-rate geometry compression methods involve three steps:
    quantization, prediction, and entropy coding.

    In VRML, geometry data is represented with 32 bit floating-point
    number, but this precision is highly beyond the perceiving
    capability of human eyes. Hence, quantization can be performed to
    compress the geometry data. Typically, each coordinate in a mesh is
    uniformly quantized to 8-16 bits integer.

    After quantization of vertex coordinates, prediction is taken in
    encoding by exploiting correlations between adjacent vertex
    coordinates. An effective prediction scheme generates prediction
    errors with highly compact distribution, which can be effectively
    encoded by entropy coders, such as Huffman coder or arithmetic
    coder. 

    More details about single-rate coding can be seen in the tutorial
    by Gotsman, Gumhold, and Kobbelt \cite{gotsman-simplification},
    the survey by Taubin \cite{3d:Taubin}, by Alliez and Gotsman
    \cite{recent:alliez}, and the survey by Peng, Kim and Kuo
    \cite{technologies:peng}.
    
    \subsection{Progressive Coding}
    Single-rate coded meshes can only be decoded after they are
    totally received, so they are not suitable for streaming. Therefore,
    some progressive coding schemes have been proposed. According to
    how the original mesh is simplified, these coding scheme can be
    categorized into three classes: progressive mesh based, vertex
    clustering based, and re-meshing based.
    
    \begin{description}
        \item[Vertex Clustering Based] 
            In vertex clustering based schemes, space is divided into cells
            following regular structure such as kd-tree \cite{566591} and 
            octree \cite{1073237}. All vertices inside a cell is represented
            by one delegate. Cells can be further divided into smaller cells
            and the quality of reconstructed model increases. Vertex clustering
            based coding can code geometry information efficiently, but it is 
            difficult to code connectivity information. Moreover, the quality
            of base mesh is poor.

        \item[Re-meshing Based]
            Re-meshing based method only keeps the shape of a model
            and does not keep the accurate topology. 
            A irregular mesh can be converted into a semi-regular mesh
            with similar shape. 
            %In a semi-regular
            %triangle mesh, the valence of most vertices is six, and therefore
            Because of the regularity of the new mesh,
            the connectivity information can be coded almost without cost.
            More details about these algorithms can be seen in the survey by Allienz and Gotsman
            \cite{recent:alliez}, the survey by Peng, Kim and Kuo
            \cite{technologies:peng} and the references therein.
            Besides losing the correct topology information,
            re-meshing based method usually code a mesh as a whole, 
            so there is no flexibility in streaming order.

        \item[Progressive Mesh Based]
            In this thesis, we concentrate on progressive meshes, which provide 
            the finest granularity in choosing streaming order and subset, 
            so we introduce the progressive mesh based coding in more details.
    \end{description}

    The progressive mesh (PM) \label{progressive_mesh}is first
    introduced by Hoppe in 1996 \cite{hoppe96progressive}. In this
    scheme, the simplification is based on \emph{edge collapse}, which
    collapses an edge into a vertex (see Figure \ref{split2}).
    After a series of edge collapse, a coarser \emph{base mesh} remains. 
    Then the PM is constructed by the base mesh and a series of \emph{vertex
    splits}, the inverse of edge collapse, in a reverse order.
    Rendering can be done in receiver side at any time after the base
    mesh is received. More vertex splits received, better
    approximation to the original mesh generated. After all
    the vertex split operations are received, the original mesh can be
    reconstructed without loss\footnote{quantization error may exist
    when quantization is taken in geometry compression.}.

    The base mesh can be encoded with the single-rate coding methods
    introduced in section \ref{single_rate}. Here, we introduce
    how to encode the vertex splits. 
\begin{figure}
\centering
\includegraphics[width=0.5\textwidth]{split2.eps}
\caption{Edge collapse and vertex split}\label{split2}
\end{figure}
    For connectivity
    information, we need to code $s$, $l$, and $r$, and for geometry
    information, we need to code the new position of $v_{s}$ and the
    position of $v_{r}$. If half collapse, which always collapse an
    edge to one of its ends (i.e. $v_{s}$ keeps unchanged), is used, 
    we only need to code the position of $v_r$. 
    
    If the number of vertices in current model is
    $V$, then $s$ can be any one of them, 
    and ${\lceil}log_{2}V{\rceil}$ bits are needed to encode $s$. 
    
    Many compression methods are proposed to reduce this cost.
    Hoppe \cite{efficient:hoppe} present an efficient implementation
    , in which the vertex splits is ordered such that next one
    is as close to current one as possible, and reduce the cost
    from $O(Vlog_{2}V)$ to $O(V)$.
    In Karni, Bogomjakov, and Gotsman's paper \cite{602153}, 
    specific order of vertex split is also used to reduce the cost of connectivity. 
    The vertex sequence is generated by recursively cut a mesh to two
    balanced part with minimum cut. With their algorithm, the connectivity can
    be encoded with in average 4.5 bpv. 

    Another idea is to group many vertex splits together, 
    and efficiency will be improved at the cost of coarser granularity. 
    Taubin, Gu\'{e}ziec, Horn, and Lazarus \cite{280834} proposed the
    progressive forest split scheme (PFS), in which several edge
    collapse operations are combined together and the inverse operation splits a
    forest of edges and vertices. 
    Payarola and Rossignac \cite{614450}, 
    proposed compressed progressive mesh (CPM)\label{cpm} with similar
    idea. They group about $50\%$ vertex splits into one batch. To
    differentiate vertices to be split with others, one bit per vertex
    is used as indicative. 
    Some more methods have the similar idea
    but based on vertex removal (remove a vertex and triangulates the hole
    generated) \cite{319358}. 

    More methods exist to reduce the cost in encoding connectivity information.
    Some of them are extended from the single rate coding algorithms
    \cite{319426, 383281}. Some extend progressive mesh to directly
    encode non-manifold meshes \cite{258852}.

    All compression methods introduced above 
    have a common drawbacks. After compression, the 
    data become linear and they have to be decoded in a fix order. 
    Therefore, these methods improve the coding efficiency at the cost
    of losing flexibility, which is essential in streaming of high-resolution
    progressive meshes.
    
    Flexibility of choosing streaming order 
    is restricted by the dependency among the vertex splits.
    For a manifold mesh, a vertex split operation depends on the existence of
    \begin{itemize}
        \item 
    the vertex to be split ($V_s$ in Figure \ref{dstream:split}), 
        \item 
    two cut neighbors ($V_l, V_r$ in Figure \ref{dstream:split}). 
    \end{itemize}
    More dependencies exist if artificial folds are strictly forbidden \cite{258843, 258847}, 
    but in this thesis we ignore these dependencies since we can 
    tolerate temporary folds in our scheme.
     
    To et al. \cite{To1999} further remove the second dependency.
    In their method, if a cut neighbor does not exist during a vertex split,
    its ancestor will be used as the cut neighbor instead.
    Kim and Lee \cite{kim01truly} improve this method so that the final mesh
    can keep the original connectivity. 
    Kim et al. \cite{multiresolution:kim} propose a better scheme that enables
    an ordinary progressive mesh to be split in random order.

    These methods increase the flexibility, however, have a low coding efficiency.
    One solution proposed by Yang et al. \cite{progressive:Yang}
    is to divide the whole mesh into several segments and encode them
    separately to trade off between flexibility and compression efficiency.
    The weakness is that the size of the base mesh is relatively large
    since the original vertices in the border of segments are kept in the base
    mesh. Furthermore, the quality of the base mesh is uneven.

    Kim et al. \cite{multiresolution:kim}
    have proposed compression algorithms that allow random splitting of a mesh without
    sacrificing compression efficiency. This method is neat since it achieves comparable
    efficiency with other compression methods but keeps the largest flexibility.
    This algorithm, however. are not designed for 
	network transmission.  We extend it in this thesis and more details are introduced
    in Chapter \ref{c:rdstream}.  
    
    \section{3D streaming}
    \label{s:related:streaming}
    Given the backgrounds in modeling and coding, now we introduce some
    related works in 3D streaming. 
    The main concern in 3D streaming is how to improve the quality of the received
    mesh as fast as possible. Current studies can be categorized to three groups
    by how to achieve this objective.
    %Three main classes of work exist 
    %-- error resilient streaming, packetization, and view-dependent streaming.
    
    \subsection{Error Resilient Streaming}
    To improve the quality quickly, we need to mitigate distortion to the 
    rendered quality of rendered mesh in the presence of packet losses.

    At the transport layer, Al-Regib and Altunbasak \cite{3tpregib}, Li
    et al. \cite{Li2006}, and Chen et al. \cite{chen05hybrid} have
    investigated how to intelligently select either TCP or UDP for
    transmissions to trade off reliability and end-to-end delay.  Li et
    al. have also considered SCTP with partial reliability.
    Harris III and Kravets \cite{harris:design} propose a new
    transport protocol that exploits loss tolerance and
    partially-ordered property of 3D objects organized into trees of
    bounding volumes.

    At the application layer, the major error control techniques: error
    resilient coding, error protection, retransmission, and error
    concealment \cite{Park2003}, have all been applied to mesh streaming.  
    %Park et al.
    %\cite{error:Park} and Yan et al. \cite{error:Yan} focus on how to best
    %segment a progressive mesh into smaller partitions such that it is
    %more resilient to losses.  Al-Regib et al. \cite{1061349} consider a
    %joint-source channel coding method to determine appropriate level of
    %error protection to use.  Chen et al. \cite{chen05hybrid} also use
    %FEC for transmission of 3D data.  Error concealment is considered by
    %Park et al. \cite{Park2003}.  
    %Cheng et al. \cite{cheng07analytical}
    %argue for retransmissions as the main error control method, while
    %Tian \cite{Tian2006} uses selective retransmission in their system.
    
    Existing work in robust mesh compression aims to
    reduce dependencies among the mesh \cite{error:Park,error:Yan}.
    Similar to introducing key frames or restart marker in video/image
    coding, mesh segmentation is used to reduce the affected range of one
    packet loss. In robust mesh compression, a mesh is typically
    divided into several independent parts and then coded separately.
    Therefore the effect of one packet loss is confined to the part to which
    it belongs. The finer the partition is, the fewer the affected vertices
    are.  The coding efficiency, however, will decrease
    due to more redundancies and less correlation.

    Al-Regib and Altunbasak \cite{unequal:Al-Regib} proposed an
    unequal error protection method to improve the resilience of
    progressive 3D mesh based on CPM (compressed progressive meshes). 
    Forward error correction (FEC) codes are added to the
    base mesh and additional levels-of-detail information to maximize 
    the decoded mesh quality.  The method is similar to FEC protection 
    of video data.

    Chen et al. \cite{chen05hybrid} also applied FEC to streaming
    progressive meshes. They analyzed several transmission schemes:
    TCP only, UDP only, TCP with UDP, and UDP with FEC, and studied
    their effects experimentally on the transmission time and decoded
    mesh quality.
    
    Some studies use retransmission to recover the packet loss.
    For example, Tian \cite{Tian2006} uses selective retransmission in their system.
    We think retransmission is more suitable than FEC when the feedback
    channel is available, because there is no playback deadline in streaming
    of 3D meshes and data is always useful.

    Most of methods introduced above treat the meshes streamed as 
    traditional linear data. When the flexibiliy of progressive mesh
    is considered, a new questions arises: how to select a sending order
    to improve the quality quickly and mitigate the effect of packet loss.
    We call it \emph{packetization} problem.
    
    \subsection{Packetization}
    \label{ss:intro:packetization}
    Packetization of different model is tackled by
    Harris III and Karvets in \cite{harris:design}.   
    They proposed a protocol named On-Demand Graphic Transport Protocol (OGP)
    for transmitting 3D models represented as a tree of bounding volumes.
    A key component of the protocol is to decide which bounding volumes
    to send.  OGP begins with packing the largest possible subtree at
    the root and continues to pack the nodes in the subtree of
    acknowledged nodes in breadth-first order.  
    
    Gu and Ooi \cite{Gu:Packetization} were the first to look at
    the packetization problem for progressive meshes.  They model
    the packetization problem as a graph problem where the objective
    is to equally partition the graph into $k$ partitions with minimum
    cut size.  The problem is shown to be NP-complete and a heuristic
    is proposed.  They, however, assume that every vertex split contributes 
    to the rendered quality equally.
    
    In practice, the contribution of vertex splits can
    vary considerably. Therefore, when choose sending order, we
    need to trade off between minimize the dependency and sending 
    vertex split has higher contribution first. To achieve this objective,
    the effect of dependency needs to be quantitatively measured.
    Before us, however, there is no study is done for this problem.

    A commonly used metric of contribution of vertex splits is 
    Hausdorff distance between the original and reconstructed mesh \cite{cignoni98metro}.
    As Hausdorff distance is view independent, 
    bandwidth may be wasted in sending invisible vertex splits
    before the visible ones. Moreover, even among the visible vertex splits,
    the view-independent metric cannot reflect the real contribution to the visual quality of
    clients with different viewpoints. A vertex split that significantly
    changes a mesh may change the rendered image 
    only slightly.  A better metric for visual contribution of a vertex split,
    based on the rendered image on the screen, 
    needs to consider the receiver's viewpoint.
    Streaming of 3D models based on this metric is named \emph{view-dependent} streaming.

    \subsection{View-Dependent Streaming}
    The view-dependent approach first appeared as 
    a dynamic simplification method used for adaptive rendering of a complex 3D mesh
    \cite{258843, 258847}. Only vertex splits that contribute to the rendered
    image will be rendered, allowing real-time rendering of a complex mesh
    even with limited rendering capability.
    Besides progressive mesh, other multi-resolution representations, 
    such as vertex-clustering  and subdivision scheme,
    are used in view-dependent refinement systems \cite{245627, efficient:Alliez,602344}.

    Later, the view-dependent approach is used in progressive 
	streaming of 3D meshes.     
    In the scheme proposed by Southern et al. \cite{363375},  the client is stateless and
    maintains only the visible data. 
    To et al. \cite{To1999}
    and Kim et al. \cite{kim:view} proposed that received data are stored
    in the receiver even after they become invisible, 
    so they need not be resent when they are visible again. 
    In these papers, view-dependent approaches mainly aim at addressing
    limited rendering capability. 
    
    Yang et al. \cite{progressive:Yang} and
    Zheng et al. \cite{zheng:interactive}, on the other hand, use
    view-dependent streaming to address limited network bandwidth.
    Yang et al. proposed a scheme where the server chooses the appropriate resolution
    according to the available network bandwidth.
    Zheng et al. \cite{zheng:interactive} use prediction to
    reduce the effect of network latency and 
    compensate the round-trip delay with the rendering time.
     
    These systems use sender-driven approach and do not address
    server scalability issues. Due to the stateful design, 
    the sender-driven approach is difficult to be extended to
    support caching proxy and peer-to-peer techniques, two 
    common solutions to scalability. Before us, there is no study about
    how to implement a scalable 
    view-dependent streaming system without incurring high infrastructural cost.

\begin{comment}
    In a view-dependent steaming system, the streaming order of data highly
    depends on the interactivity of users. Designing a satisfying system
    requires a understanding of user behaviors in viewing 3D meshes.
    Most previous work on user interactions with 3D objects focused on design
    of specific interaction techniques (e.g., the study by Chen et al. \cite{chen88study}
    and Hinckley et al. \cite{hinckley97usability}). 
    As far as we know, there is no studies before us which study user behavior
    from the system design point of view.
\end{comment}
    

%\include{mesh}
%\include{dstream}
%\include{mm09-3dstreaming}
%\include{p2p}

\begin{comment}
\chapter{Conclusion}
\label{c:conclusion}
This research concentrated on streaming of progressive meshes over network. 
First, the effect of dependency over lossy network was quantitatively analyzed. 
To enable quantitative analysis, an analytical model was developed to compute 
the probability distribution of the decoding time of each vertex split. 
Many experiments were carried out to verify the accuracy of the analytical model, 
and different network traces and progressive meshes were used to avoid bias. 
In these experiments, the predicted decoding time of vertex splits obtained 
with the analytical model was reasonably close to the measured one. 
Therefore, with the help of the analytical model, 
the quality of the received mesh could be predicted efficiently before transmission.
Consequently, adaptive transmitting vertex splits according to the network condition
becomes possible. Besides streaming of progressive meshes, 
streaming of other partially ordered data could also be modeled
with the analytical model in this thesis. 
For example, this model was successfully applied in streaming of 3D plants.

The analytical model in this thesis assumes that the packet losses 
are independent with each other, 
so a network trace with many burst packet losses may cause considerable error in the prediction. 
Gilbert model of packet loss may be used to obtain results that are more accurate, 
but using Gilbert model may significantly increase the complexity of the analytical model. 
Moreover, burst packet losses happen less commonly in the Internet
after widespread application of RED in routers. 
Therefore, the precision of the analytical model
without considering burst packet loss may be acceptable in most cases now.

It is observed in the experiments that the effect of dependency
is only significant in the short period at the beginning of transmission, 
and the length of this period increases
when the round trip time or packet loss rate increases. 
This observation is consistent with the result of the analytical model. 
Since each lost packet will be retransmitted as soon as the packet loss is detected, 
the effect of a packet loss is restricted to a certain period. 
This effect decreases with time because of two reasons. 
First, the contribution of the vertex splits sent decreases; 
second, the quality of the reconstructed mesh increases. 
Consequently, the relative value of the effect, 
represented as the ratio of the contribution of vertex
splits to the quality of the reconstructed mesh, decreases.
As a result, considering the dependency among the vertex splits 
is only needed for applications requiring high interactivity
because these applications require low initial latency. 
For these applications, the greedy method proposed in this thesis
could generate a adaptive sending strategy to reduce the initial latency. 

View-dependent streaming is needed in streaming of large meshes
to improve the quality quickly, but current implementations cannot be easily scaled
to large number of receivers because the sender is not stateless. 
To address this weakness, a receiver-driven view-dependent streaming system,
in which the sender is stateless, was proposed in this thesis. 
According to the experimental results, the receiver-driven approach
can reduce both the CPU usage and outgoing bandwidth of the sender significantly. 
Moving the visibility decision to the receiver reduces the overhead of the server. 
Moreover, it also reduces the outgoing bandwidth of the sender because the server
does not need to send the identifications of the vertex splits any more. 
Above all, a significant advantage of receiver-driven approach is that
now both the caching proxy and P2P techniques can be applied to increase the scalability of the system
because of the sender is stateless. 

The visibility decision made by the receiver may not be accurate 
because the receiver can only estimate the visibility based on
the partially received mesh. 
Visible vertices may be not displayed if their ancestor vertices are not visible. 
According to the current results, however, this kind of error is negligible in most cases. 
For applications that tolerate no error, 
further research could be done to remove this kind of error. 
A possible solution could be to split those vertices near the silhouette even when they are invisible.

To increase the scalability of the view-dependent mesh-streaming systems, 
a P2P mesh streaming system was proposed in this thesis based on the receiver-driven approach. 
According to the experimental results, the server overhead can be reduced by 90\%
and the response time is still close to the low bound. 
The control overhead introduced in this system is about 10\%, a reasonable value. 
The response time is low because most requests in this system are successful in the first try, 
and the message overhead is reasonable because the hierarchical group system proposed in this thesis effectively 
reduces the message overhead. 
The prototype developed in this thesis shows that P2P mesh streaming system is feasible
and it can significantly reduce the server cost when there are many clients.

The control overhead at 10\% is acceptable in this system since the majority of
control messages are transmitted among the peers and the server overhead keeps low. 
Nonetheless, the message overhead could be further reduced. 

During the study, it is found that in some cases the bottleneck can be the rendering of the meshes, 
especially when the graphic card is used in deciding the visibility of vertices. 
Improving the rendering efficiency of the progressive mesh during the streaming 
could be an interesting research problem.  
During the streaming, a progressive mesh with only partial modification is frequently re-rendered, 
so it is possible to exploit the similarity between two consecutive meshes to improve the rendering speed.
\end{comment}
\bibliographystyle{abbrv}
\bibliography{thesis}
\end{document}
